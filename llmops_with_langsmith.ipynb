{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Requirements:\n",
    "\n",
    "\n",
    "Definition of Environment Variables\n",
    "- OPENAI_API_KEY= [openai api key]\n",
    "- OPENAI_ORGANIZATION=[organization key]\n",
    "- LANGCHAIN_TRACING_V2=true\n",
    "- LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "- LANGCHAIN_API_KEY=[ langsmith apikey]\n",
    "- LANGCHAIN_PROJECT=[project name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain langsmith\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv,load_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@traceable\n",
    "def get_response(user_input: str):\n",
    "    result = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "response = get_response(\"What is LLMops in Machine Learning? What are the best tools for LLMops operation?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "\n",
    "client = wrap_openai(openai.Client())\n",
    "\n",
    "@traceable\n",
    "def openai_response(system_prompt: str, user_input: str):\n",
    "    result = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\",\"content\":user_input}],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.5,\n",
    "        frequency_penalty=0.1,\n",
    "        timeout=5,\n",
    "\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are an eloquent travel assistant. Your task is to recommend best cities for a vacation to users based on the requirements of the user. Understand the requirements and also recommend the things users need to carry with them to travel to the given cities.'''\n",
    "user_prompt = '''I want to travel in February. The city must not be freezing cold neither too hot to travel. Asian Cities will be preferred.'''\n",
    "response = openai_response(system_prompt,user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods of Dataset Creation:\n",
    "1. Importing CSV files\n",
    "2. Through Existing Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "example_inputs = [\n",
    "  (\"What is the largest mammal?\", \"The blue whale\"),\n",
    "  (\"What do mammals and birds have in common?\", \"They are both warm-blooded\"),\n",
    "  (\"What are reptiles known for?\", \"Having scales\"),\n",
    "  (\"What's the main characteristic of amphibians?\", \"They live both in water and on land\"),\n",
    "]\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"Elementary Animal Questions\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name, description=\"Questions and answers about animal phylogenetics.\",\n",
    ")\n",
    "for input_prompt, output_answer in example_inputs:\n",
    "    client.create_example(\n",
    "        inputs={\"question\": input_prompt},\n",
    "        outputs={\"answer\": output_answer},\n",
    "        metadata={\"source\": \"Wikipedia\"},\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"run1\"\n",
    "\n",
    "runs = client.list_runs(\n",
    "    project_name=os.environ.get('LANGCHAIN_PROJECT'),\n",
    "    execution_order=1,\n",
    "    error=False,\n",
    ")\n",
    "\n",
    "dataset = client.create_dataset(dataset_name, description=\"Dataset creation using Runs\")\n",
    "for run in runs:\n",
    "    client.create_example(\n",
    "        inputs=run.inputs,\n",
    "        outputs=run.outputs,\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation by Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langchain_openai import chat_models\n",
    "from langchain import prompts, smith\n",
    "from langchain.schema import output_parser\n",
    "\n",
    "\n",
    "# Define your runnable or chain below.\n",
    "system_prompt = \"\"\"You are an eloquent travel assistant. Your task is to recommend best cities for a vacation to users based on the requirements of the user. Understand the requirements and also recommend the things users need to carry with them to travel to the given cities.\"\"\"\n",
    "user_prompt = \"\"\"I want to travel in February. The city must not be freezing cold neither too hot to travel. Asian Cities will be preferred.\"\"\"\n",
    "prompt = prompts.ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"human\", \"{user_input}\")]\n",
    ")\n",
    "llm = chat_models.ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "chain = prompt | llm | output_parser.StrOutputParser()\n",
    "\n",
    "client = Client()\n",
    "\n",
    "\n",
    "results = client.run_on_dataset(\n",
    "    dataset_name=\"langsmith_dataset\",\n",
    "    llm_or_chain_factory=chain,\n",
    "    project_name=\"langsmith_eval5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation by LangSmith Evaluators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation in Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"How does that apply?\",\n",
    "            \"chat_history\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"I’m trying tto uunderstand instein’s theory.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Which one? He's known for several theories.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": \"Thee one about time and spae.\"},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Ah, you're referring to the theory of relativity. There are two parts: special and general. Which one?\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"expected\": \"Special relativity, proposed by Einstein in 1905, deals with objects in uniform motion, especially those moving at the speed of light. It introduced the idea that time and space are relative and can change in relation to each other. For instance, time can appear to move slower for an object moving close to the speed of light.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"What's the main difference?\",\n",
    "            \"chat_history\": [\n",
    "                {\"role\": \"user\", \"content\": \"Can yyou contrast DNA and RNA for me?\"},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Certainly. DNA and RNA are both nucleic acids but have different roles, structures, and properties. Do you want specifics?\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"expected\": \"The main structural differences between DNA and RNA include: 1) DNA is double-stranded while RNA is single-stranded. 2) The sugar in the backbone of RNA is ribose, whereas in DNA it's deoxyribose. 3) DNA uses the bases adenine (A), cytosine (C), guanine (G), and thymine (T); RNA uses adenine (A), cytosine (C), guanine (G), and uracil (U) instead of thymine.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"what led them to such a draastic action?\",\n",
    "            \"chat_history\": [\n",
    "                {\"role\": \"user\", \"content\": \"tell me about the Boston Tea Party.\"},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"The Boston Tea Party was a political protest by the American colonists against the British government in 1773. They were protesting the Tea Act, which allowed the British East India Company to sell tea directly to the colonies, bypassing colonial merchants.\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"expected\": \"The colonists undertook the Boston Tea Party as a drastic action due to multiple reasons: 1) They believed the Tea Act was a violation of their rights as Englishmen, as they were being taxed without their consent. 2) The act gave the British East India Company a monopoly on tea sales, threatening local businesses. 3) The act was seen as another example of the British government's increasing interference in colonial affairs. The protest was a way to show their strong opposition to British policies.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"thats a scary one. can it be avoideed?\",\n",
    "            \"chat_history\": [\n",
    "                {\"role\": \"user\", \"content\": \"I'm learning bout genetic disorders.\"},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Genetic disorders are diseases caused by abnormalities in an individual's DNA. They can be inherited or result from mutations. One common one is Huntington's disease.\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"expected\": \"Huntington's disease is a hereditary genetic disorder caused by a mutation in the HTT gene. If a person inherits the defective gene, they will eventually develop the disease. Currently, there's no cure for Huntington's, but its onset can be delayed with treatment. Genetic counseling and testing can help prospective parents understand the risks of passing the mutation to their offspring.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"question\": \"Which one?\",\n",
    "            \"chat_history\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"I'm confused aboutt stars. what even aaaare they?\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Stars are celestial bodies made mostly of hydrogen and helium. They generate light and heat through nuclear fusion in their cores.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"there''s a classification based on theirbrightness, right?\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Yes\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"outputs\": {\n",
    "            \"expected\": \"Yes, stars are classified based on their brightness using a system called the Hertzsprung-Russell (H-R) diagram. In this diagram, stars are categorized into main-sequence stars, giants, supergiants, and white dwarfs, based on their luminosity and temperature. The Sun, for instance, is a main-sequence star.\"\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import uuid\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = f\"Chat Bot Evals Single-Turn Example - {uuid.uuid4()}\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[e[\"inputs\"] for e in examples],\n",
    "    outputs=[e[\"outputs\"] for e in examples],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# An example chain\n",
    "chain = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a helpful tutor AI.\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.adapters.openai import convert_openai_messages\n",
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def predict(inputs: dict):\n",
    "    return chain.invoke(\n",
    "        {\n",
    "            \"input\": inputs[\"question\"],\n",
    "            \"chat_history\": convert_openai_messages(inputs[\"chat_history\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def format_evaluator_inputs(run: Run, example: Example):\n",
    "    return {\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "        \"prediction\": next(iter(run.outputs.values())),\n",
    "        \"reference\": example.outputs[\"expected\"],\n",
    "    }\n",
    "\n",
    "\n",
    "correctness_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_score_string\",\n",
    "    config={\"criteria\": \"correctness\", \"normalize_by\": 10},\n",
    "    prepare_data=format_evaluator_inputs,\n",
    ")\n",
    "\n",
    "results = evaluate(\n",
    "    predict,\n",
    "    data=dataset_name,\n",
    "    experiment_prefix=\"Chat Single Turn\",\n",
    "    evaluators=[correctness_evaluator],\n",
    "    metadata={\"model\": \"gpt-3.5-turbo\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation from Run Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "from langchain import prompts,smith\n",
    "from langchain.schema import output_parser\n",
    "\n",
    "system_prompt = '''You are an eloquent travel assistant. Your task is to recommend best cities for a vacation to users based on the requirements of the user. Understand the requirements and also recommend the things users need to carry with them to travel to the given cities.'''\n",
    "user_prompt = '''I want to travel in February. The city must not be freezing cold neither too hot to travel. Asian Cities will be preferred.'''\n",
    "prompt = prompts.ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{user_input}\")\n",
    "  ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "chain = prompt | llm | output_parser.StrOutputParser()\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        \"qa\",\n",
    "        \"context_qa\",\n",
    "        \"cot_qa\",\n",
    "    ],\n",
    "    reference_key=\"output\",\n",
    "    input_key=\"user_input\",\n",
    ")\n",
    "\n",
    "client = Client()\n",
    "run_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=\"langsmith_dataset\",\n",
    "    llm_or_chain_factory=chain,\n",
    "    evaluation=evaluation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"What is LLMOps in Machine Learning? What are the best tools for LLMOps operation?\"\n",
    "\n",
    "q2 = \"What is the difference between MLOps and LLMOps in Machine Learning\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "import uuid\n",
    "\n",
    "client = openai.Client()\n",
    "# define session id\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "# define function for call\n",
    "@traceable(\n",
    "    run_type=\"chain\",\n",
    "    name=\"OpenAI Assistant\",\n",
    ")\n",
    "def assistant(messages: list[dict]):\n",
    "    return (\n",
    "        client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a Machine Learning assistant specialized in MLOps.\"}]\n",
    "            + messages,\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message\n",
    "    )\n",
    "\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": q1}]\n",
    "response = assistant(messages, langsmith_extra={\"metadata\": {\"session_id\": session_id}})\n",
    "messages = messages + [response, {\"role\": \"user\", \"content\": q2}]\n",
    "response = assistant(messages, langsmith_extra={\"metadata\": {\"session_id\": session_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
